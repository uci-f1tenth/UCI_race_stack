\chapter{Implementation Details}

This chapter details the core logic behind integrating the F1tenth autonomous race car with the DreamerV3 reinforcement learning agent. It explains the structure of the DreamerV3 codebase, how we adapt it for the F1tenth platform using ROS2 Humble, the importance of data type compatibility and normalization, and outlines the high-level implementation goals and timeline.

\section{DreamerV3 Codebase Structure}

The DreamerV3 codebase is designed with a hyperparameter-driven approach, with its main function located in \texttt{dream.py}.  It utilizes OpenAI Gymnasium environments to define the observation space, action space, the \texttt{step()} function (which interacts with the environment), and the \texttt{reset()} function (to reset the environment).  Wrappers are employed to configure these environments and perform necessary data preprocessing.

A typical DreamerV3 environment definition looks like this (example from the Crafter environment):

\begin{verbatim}
import gym
import numpy as np

class Crafter:
    # ... (metadata and initialization) ...

    @property
    def observation_space(self):
        # ... (defines the structure of the observation) ...

    @property
    def action_space(self):
        # ... (defines the structure of the action) ...

    def step(self, action):
        # ... (interacts with environment based on action) ...

    def reset(self):
        # ... (resets the underlying environment) ...
\end{verbatim}

Wrappers, like the `NormalizeActions` wrapper in the DreamerV3 examples, can be used to modify the environment (like normalizing the action space).

\section{Adapting DreamerV3 for F1tenth with ROS2 Humble}

Our primary goal is to replace the standard DreamerV3 environment (like Crafter) with an interface to the F1tenth car within the ROS2 Humble framework.  This involves creating a custom Gymnasium environment, \texttt{racerenv.py}, that acts as a bridge between DreamerV3 and ROS2.  This environment will not directly handle ROS2 communication.  Instead, a separate ROS2 node, \texttt{dreamer\_node.py}, will manage all ROS2 interactions (subscribing to LiDAR and Odometry data, publishing motor commands) and pass the processed data to \texttt{racerenv.py}.

\subsection{Data Flow and Compatibility}

The \texttt{dreamer\_node.py} will subscribe to the relevant ROS2 topics:
\begin{itemize}
    \item \texttt{/scan}:  For LiDAR data.
    \item \texttt{/odom}: For Odometry data.
    \item \texttt{/drive}: To publish drive commands.
\end{itemize}

The \texttt{dreamer\_node.py} will then process the received ROS2 messages.  The LiDAR data (a 1D array of floats) and Odometry data will be extracted and passed to the \texttt{racerenv.py}'s \texttt{step()} and \texttt{reset()} methods.  The actions generated by the DreamerV3 agent will be passed from \texttt{racerenv.py} to \texttt{dreamer\_node.py}, which will then publish them as messages to the \texttt{/drive} topic.

\subsection{Data Normalization}

Data normalization is crucial for stable and effective reinforcement learning.  Raw sensor data (LiDAR, Odometry) often has a wide range of values, which can make it difficult for the agent to learn.  We normalize the LiDAR data to a range of [0, 1] within the \texttt{racerenv.py} environment.  The action space (steering and speed) is also normalized to a range of [-1, 1]. This ensures that both the input and output of the DreamerV3 agent are within a consistent and manageable range.  The denormalization of the actions (from [-1,1] to the cars physical limits) happens in the `step` function before being published to the car.

\section{Implementation Goals and Timeline}

Our primary goals for this project are:

\begin{itemize}
    \item Create a robust and efficient interface between the F1tenth car and DreamerV3.
    \item Train the DreamerV3 agent to successfully navigate the F1tenth car in various simulated environments.
    \item Evaluate the performance of the trained agent using appropriate metrics.
    \item Document the project thoroughly.
\end{itemize}

The project timeline is divided into the following phases:

\begin{enumerate}
    \item \textbf{Environment and ROS2 Integration:} Implementing \texttt{racerenv.py} and \texttt{dreamer\_node.py}, establishing ROS2 communication.
    \item \textbf{DreamerV3 Adaptation:} Integrating \texttt{racerenv.py} with the DreamerV3 training loop, adapting networks.py, implementing the reward function.
    \item \textbf{Isaac Lab Migration}: Migration to Isaac Lab since F1Tenth Gym is proved to be unreliable.
    \item \textbf{Training and Evaluation:} Training the agent, tuning hyperparameters, evaluating performance in simulation.
    \item \textbf{Testing and Refinement:} Testing in more complex scenarios, refining the code, and documenting the project.
\end{enumerate}

This timeline is subject to change based on project progress and any unforeseen challenges.  Regular team meetings and communication will be essential to ensure the project stays on track.